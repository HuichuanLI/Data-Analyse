{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sl:satisfaction_level---False:MinMaxScaler;True:StandardScaler\n",
    "#le:last_evaluation---False:MinMaxScaler;True:StandardScaler\n",
    "#npr:number_project---False:MinMaxScaler;True:StandardScaler\n",
    "#amh:average_monthly_hours--False:MinMaxScaler;True:StandardScaler\n",
    "#tsc:time_spend_company--False:MinMaxScaler;True:StandardScaler\n",
    "#wa:Work_accident--False:MinMaxScaler;True:StandardScaler\n",
    "#pl5:promotion_last_5years--False:MinMaxScaler;True:StandardScaler\n",
    "#dp:department--False:LabelEncoding;True:OneHotEncoding\n",
    "#slr:salary--False:LabelEncoding;True:OneHotEncoding\n",
    "def map_salary(s):\n",
    "    d=dict([(\"low\",0),(\"medium\",1),(\"high\",2)])\n",
    "    return d.get(s,0)\n",
    "def hr_preprocessing(sl=False,le=False,npr=False,amh=False,tsc=False,wa=False,pl5=False,dp=False,slr=False,lower_d=False,ld_n=1):\n",
    "    df=pd.read_csv(\"./data/HR.csv\")\n",
    "    \n",
    "    #1、清洗数据\n",
    "    df=df.dropna(subset=[\"satisfaction_level\",\"last_evaluation\"])\n",
    "    df=df[df[\"satisfaction_level\"]<=1][df[\"salary\"]!=\"nme\"]\n",
    "    #2、得到标注\n",
    "    label = df[\"left\"]\n",
    "    df = df.drop(\"left\", axis=1)\n",
    "    #3、特征选择\n",
    "    #4、特征处理\n",
    "    scaler_lst=[sl,le,npr,amh,tsc,wa,pl5]\n",
    "    column_lst=[\"satisfaction_level\",\"last_evaluation\",\"number_project\",\\\n",
    "                \"average_monthly_hours\",\"time_spend_company\",\"Work_accident\",\\\n",
    "                \"promotion_last_5years\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=\\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=\\\n",
    "                StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    scaler_lst=[slr,dp]\n",
    "    column_lst=[\"salary\",\"department\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i]==\"salary\":\n",
    "                # low 为0,medium为1，high为2\n",
    "                df[column_lst[i]]=[map_salary(s) for s in df[\"salary\"].values]\n",
    "            else:\n",
    "                df[column_lst[i]]=LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df=pd.get_dummies(df,columns=[column_lst[i]])\n",
    "    if lower_d:\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values),label  \n",
    "    return df,label            \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "features,label = hr_preprocessing(sl=True,le=True,npr=True,amh=True,tsc=True,wa=True,pl5=True,dp=True,slr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.03436583  1.13282545  0.97111292 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.14948968  0.3733173   0.15978764 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.83325762  0.49016471  0.97111292 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.3505979   0.66543582  0.15978764 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.18971132 -1.3209701   0.15978764 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.94203577 -0.38619085  0.15978764 ...  0.          1.\n",
      "   0.        ]]\n",
      "8999 8999 None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def hr_modeling_nn(features,label):\n",
    "    f_v = features.values\n",
    "    f_names = features.columns.values\n",
    "    l_v = label.values\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    print(len(X_train),len(X_train),print(X_validation))\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test,X_validation, Y_validation\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test,X_validation, Y_validation = hr_modeling_nn(features,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习 --分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN -ACC: 0.9486666666666667\n",
      "KNN -REC: 0.9286713286713286\n",
      "KNN -F1: 0.8960863697705802\n",
      "GaussianNB -ACC: 0.6603333333333333\n",
      "GaussianNB -REC: 0.8125874125874126\n",
      "GaussianNB -F1: 0.5327831270059605\n",
      "BernoulliNB -ACC: 0.7553333333333333\n",
      "BernoulliNB -REC: 0.17902097902097902\n",
      "BernoulliNB -F1: 0.2585858585858586\n",
      "DecisionTreeGini -ACC: 0.9693333333333334\n",
      "DecisionTreeGini -REC: 0.9594405594405594\n",
      "DecisionTreeGini -F1: 0.9371584699453551\n",
      "DecisionTreeEntropy -ACC: 0.9726666666666667\n",
      "DecisionTreeEntropy -REC: 0.9552447552447553\n",
      "DecisionTreeEntropy -F1: 0.9433701657458564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier -ACC: 0.9716666666666667\n",
      "SVM Classifier -REC: 0.9328671328671329\n",
      "SVM Classifier -F1: 0.9400986610288935\n",
      "OriginalRandomForest -ACC: 0.9856666666666667\n",
      "OriginalRandomForest -REC: 0.9524475524475524\n",
      "OriginalRandomForest -F1: 0.9693950177935944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest -ACC: 0.985\n",
      "RandomForest -REC: 0.9566433566433566\n",
      "RandomForest -F1: 0.9681528662420383\n",
      "Adaboost -ACC: 0.9516666666666667\n",
      "Adaboost -REC: 0.8895104895104895\n",
      "Adaboost -F1: 0.8976711362032463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression -ACC: 0.788\n",
      "LogisticRegression -REC: 0.34545454545454546\n",
      "LogisticRegression -F1: 0.43716814159292033\n",
      "GBDT -ACC: 0.985\n",
      "GBDT -REC: 0.9538461538461539\n",
      "GBDT -F1: 0.9680624556422995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "    \n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "f_v=features.values\n",
    "f_names=features.columns.values\n",
    "    \n",
    "# # mdl = Sequential()\n",
    "# # mdl.add(Dense(50,input_dim=len(f_v[0])))\n",
    "# # mdl.add(Activation(\"sigmoid\"))\n",
    "# # mdl.add(Dense(2))\n",
    "# # mdl.add(Activation(\"softmax\"))\n",
    "# # sgd=SGD(learning_rate=0.05)\n",
    "# # mdl.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\n",
    "# # mdl.fit(X_train,np.array([[0,1] if i==1 else [1,0] for i in Y_train]),nb_epoch=2000,batch_size=2048)\n",
    "# xy_lst=[(X_train,Y_train),(X_validation,Y_validation),(X_test,Y_test)]\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_auc_score,roc_curve\n",
    "# f = plt.figure()\n",
    "# for i in range(len(xy_lst)):\n",
    "#     X_part=xy_lst[i][0]\n",
    "#     Y_part=xy_lst[i][1]\n",
    "# #     Y_pred=mdl.predict_classes(X_part)\n",
    "#     Y_pred=mdl.predict(X_part)\n",
    "#     Y_pred= np.array(Y_pred[:,1]).reshape((1,-1))[0]\n",
    "# #     print(i)\n",
    "# #     print(\"NN\",\"-ACC:\",accuracy_score(Y_part,Y_pred))\n",
    "# #     print(\"NN\",\"-REC:\",recall_score(Y_part,Y_pred))\n",
    "# #     print(\"NN\",\"-F1:\",f1_score(Y_part,Y_pred)) \n",
    "#     f.add_subplot(1,3,i+1)\n",
    "#     fpr,tpr,threshold = roc_curve(Y_part,Y_pred)\n",
    "#     plt.plot(fpr,tpr)\n",
    "#     print(\"NN\",\"-AUC:\",auc(Y_part,Y_pred)) \n",
    "#     print(\"NN\",\"-AUC_score:\",roc_auc_score(Y_part,Y_pred)) \n",
    "# plt.show()\n",
    "# return\n",
    "models = []\n",
    "models.append((\"KNN\",KNeighborsClassifier(n_neighbors=3,n_jobs=-1)))\n",
    "models.append((\"GaussianNB\",GaussianNB()))\n",
    "models.append((\"BernoulliNB\",BernoulliNB()))\n",
    "models.append((\"DecisionTreeGini\",DecisionTreeClassifier()))\n",
    "models.append((\"DecisionTreeEntropy\",DecisionTreeClassifier(criterion=\"entropy\")))\n",
    "models.append((\"SVM Classifier\",SVC(C=1000)))\n",
    "models.append((\"OriginalRandomForest\",RandomForestClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier(n_estimators=11,max_features=None,n_jobs=-1)))\n",
    "models.append((\"Adaboost\",AdaBoostClassifier(n_estimators=100)))\n",
    "# sag 随机梯度下降\n",
    "models.append((\"LogisticRegression\",LogisticRegression(C=1000,tol=1e-10,solver=\"sag\",max_iter=1000)))\n",
    "models.append((\"GBDT\",GradientBoostingClassifier(max_depth=6,n_estimators=100)))\n",
    "  \n",
    "      \n",
    "for clf_name,clf in models:\n",
    "    clf.fit(X_train,Y_train)\n",
    "    xy_lst=[(X_train,Y_train),(X_validation,Y_validation),(X_test,Y_test)]\n",
    "    for i in range(len(xy_lst)):\n",
    "        X_part=xy_lst[i][0]\n",
    "        Y_part=xy_lst[i][1]\n",
    "        Y_pred=clf.predict(X_part)\n",
    "        if i ==2:\n",
    "            print(clf_name,\"-ACC:\",accuracy_score(Y_part,Y_pred))\n",
    "            print(clf_name,\"-REC:\",recall_score(Y_part,Y_pred))\n",
    "            print(clf_name,\"-F1:\",f1_score(Y_part,Y_pred)) \n",
    "#         if clf_name.startswith(\"DecisionTree\"):\n",
    "#             dot_data=StringIO()\n",
    "#             export_graphviz(clf,out_file=dot_data,\n",
    "#                                      feature_names=f_names,\n",
    "#                                      class_names=[\"NL\",\"L\"],\n",
    "#                                      filled=True,\n",
    "#                                      rounded=True,\n",
    "#                                      special_characters=True)\n",
    "#             graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "#             graph.write_pdf(\"dt_tree_%s.pdf\"%(clf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [-0.16009483  0.01494029 -0.04196149  0.03202485  0.05320615 -0.05465984\n",
      " -0.01616189 -0.10639539  0.09246624  0.01392915 -0.01076429 -0.06050522\n",
      "  0.0146708   0.04922629 -0.04760503  0.0122534  -0.00939767  0.00951584\n",
      "  0.02061428  0.0219916 ]\n",
      "MSE: 0.1423090302994102\n",
      "MAE: 0.3019494008573236\n",
      "R2: 0.21549270259168452\n"
     ]
    }
   ],
   "source": [
    "# print(\"X\",features)\n",
    "# print(\"Y\",label)\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "#regr=LinearRegression()\n",
    "regr=Ridge(alpha=1)\n",
    "regr.fit(features.values,label.values)\n",
    "Y_pred=regr.predict(features.values)\n",
    "print(\"Coef:\",regr.coef_)\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "print(\"MSE:\",mean_squared_error(label.values,Y_pred))\n",
    "print(\"MAE:\",mean_absolute_error(label.values,Y_pred))\n",
    "print(\"R2:\",r2_score(label.values,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}