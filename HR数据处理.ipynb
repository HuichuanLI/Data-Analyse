{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sl:satisfaction_level---False:MinMaxScaler;True:StandardScaler\n",
    "#le:last_evaluation---False:MinMaxScaler;True:StandardScaler\n",
    "#npr:number_project---False:MinMaxScaler;True:StandardScaler\n",
    "#amh:average_monthly_hours--False:MinMaxScaler;True:StandardScaler\n",
    "#tsc:time_spend_company--False:MinMaxScaler;True:StandardScaler\n",
    "#wa:Work_accident--False:MinMaxScaler;True:StandardScaler\n",
    "#pl5:promotion_last_5years--False:MinMaxScaler;True:StandardScaler\n",
    "#dp:department--False:LabelEncoding;True:OneHotEncoding\n",
    "#slr:salary--False:LabelEncoding;True:OneHotEncoding\n",
    "def map_salary(s):\n",
    "    d=dict([(\"low\",0),(\"medium\",1),(\"high\",2)])\n",
    "    return d.get(s,0)\n",
    "def hr_preprocessing(sl=False,le=False,npr=False,amh=False,tsc=False,wa=False,pl5=False,dp=False,slr=False,lower_d=False,ld_n=1):\n",
    "    df=pd.read_csv(\"./data/HR.csv\")\n",
    "    \n",
    "    #1、清洗数据\n",
    "    df=df.dropna(subset=[\"satisfaction_level\",\"last_evaluation\"])\n",
    "    df=df[df[\"satisfaction_level\"]<=1][df[\"salary\"]!=\"nme\"]\n",
    "    #2、得到标注\n",
    "    label = df[\"left\"]\n",
    "    df = df.drop(\"left\", axis=1)\n",
    "    #3、特征选择\n",
    "    #4、特征处理\n",
    "    scaler_lst=[sl,le,npr,amh,tsc,wa,pl5]\n",
    "    column_lst=[\"satisfaction_level\",\"last_evaluation\",\"number_project\",\\\n",
    "                \"average_monthly_hours\",\"time_spend_company\",\"Work_accident\",\\\n",
    "                \"promotion_last_5years\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=\\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=\\\n",
    "                StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    scaler_lst=[slr,dp]\n",
    "    column_lst=[\"salary\",\"department\"]\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i]==\"salary\":\n",
    "                # low 为0,medium为1，high为2\n",
    "                df[column_lst[i]]=[map_salary(s) for s in df[\"salary\"].values]\n",
    "            else:\n",
    "                df[column_lst[i]]=LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df=pd.get_dummies(df,columns=[column_lst[i]])\n",
    "    if lower_d:\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values),label  \n",
    "    return df,label            \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "features,label = hr_preprocessing(sl=True,le=True,npr=True,amh=True,tsc=True,wa=True,pl5=True,dp=True,slr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.23547405 -1.3209701   0.97111292 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.47126283  1.42494396  0.97111292 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.25272675 -0.67830936 -0.65153764 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.73538647  0.25646989  1.7824382  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.02882475  1.60021507  0.15978764 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.35613898 -0.03564863  0.15978764 ...  1.          0.\n",
      "   0.        ]]\n",
      "8999 8999 None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def hr_modeling_nn(features,label):\n",
    "    f_v = features.values\n",
    "    f_names = features.columns.values\n",
    "    l_v = label.values\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    print(len(X_train),len(X_train),print(X_validation))\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test,X_validation, Y_validation\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test,X_validation, Y_validation = hr_modeling_nn(features,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习 --分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KNN -ACC: 0.9737748638737638\n",
      "KNN -REC: 0.9591930307198533\n",
      "KNN -F1: 0.946606334841629\n",
      "1\n",
      "KNN -ACC: 0.9433333333333334\n",
      "KNN -REC: 0.9049586776859504\n",
      "KNN -F1: 0.8854447439353099\n",
      "2\n",
      "KNN -ACC: 0.9433333333333334\n",
      "KNN -REC: 0.9126506024096386\n",
      "KNN -F1: 0.8769898697539797\n",
      "0\n",
      "GaussianNB -ACC: 0.6506278475386154\n",
      "GaussianNB -REC: 0.8541953232462174\n",
      "GaussianNB -F1: 0.5423580786026202\n",
      "1\n",
      "GaussianNB -ACC: 0.6533333333333333\n",
      "GaussianNB -REC: 0.8347107438016529\n",
      "GaussianNB -F1: 0.5381882770870338\n",
      "2\n",
      "GaussianNB -ACC: 0.6496666666666666\n",
      "GaussianNB -REC: 0.8192771084337349\n",
      "GaussianNB -F1: 0.5086489013557738\n",
      "0\n",
      "BernoulliNB -ACC: 0.7609734414934993\n",
      "BernoulliNB -REC: 0.2347546996790463\n",
      "BernoulliNB -F1: 0.3225196850393701\n",
      "1\n",
      "BernoulliNB -ACC: 0.754\n",
      "BernoulliNB -REC: 0.2066115702479339\n",
      "BernoulliNB -F1: 0.2890173410404624\n",
      "2\n",
      "BernoulliNB -ACC: 0.772\n",
      "BernoulliNB -REC: 0.21536144578313254\n",
      "BernoulliNB -F1: 0.2948453608247423\n",
      "0\n",
      "DecisionTreeGini -ACC: 1.0\n",
      "DecisionTreeGini -REC: 1.0\n",
      "DecisionTreeGini -F1: 1.0\n",
      "1\n",
      "DecisionTreeGini -ACC: 0.9753333333333334\n",
      "DecisionTreeGini -REC: 0.9614325068870524\n",
      "DecisionTreeGini -F1: 0.9496598639455783\n",
      "2\n",
      "DecisionTreeGini -ACC: 0.9756666666666667\n",
      "DecisionTreeGini -REC: 0.9563253012048193\n",
      "DecisionTreeGini -F1: 0.945644080416977\n",
      "0\n",
      "DecisionTreeEntropy -ACC: 1.0\n",
      "DecisionTreeEntropy -REC: 1.0\n",
      "DecisionTreeEntropy -F1: 1.0\n",
      "1\n",
      "DecisionTreeEntropy -ACC: 0.9736666666666667\n",
      "DecisionTreeEntropy -REC: 0.9628099173553719\n",
      "DecisionTreeEntropy -F1: 0.946513202437373\n",
      "2\n",
      "DecisionTreeEntropy -ACC: 0.9756666666666667\n",
      "DecisionTreeEntropy -REC: 0.9548192771084337\n",
      "DecisionTreeEntropy -F1: 0.9455630126771065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SVM Classifier -ACC: 0.9882209134348261\n",
      "SVM Classifier -REC: 0.9674461256304447\n",
      "SVM Classifier -F1: 0.9754969949144707\n",
      "1\n",
      "SVM Classifier -ACC: 0.9646666666666667\n",
      "SVM Classifier -REC: 0.928374655647383\n",
      "SVM Classifier -F1: 0.9270976616231086\n",
      "2\n",
      "SVM Classifier -ACC: 0.9676666666666667\n",
      "SVM Classifier -REC: 0.9352409638554217\n",
      "SVM Classifier -F1: 0.9275578790141896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "OriginalRandomForest -ACC: 0.9977775308367597\n",
      "OriginalRandomForest -REC: 0.9912883998165979\n",
      "OriginalRandomForest -F1: 0.9953959484346225\n",
      "1\n",
      "OriginalRandomForest -ACC: 0.9863333333333333\n",
      "OriginalRandomForest -REC: 0.9559228650137741\n",
      "OriginalRandomForest -F1: 0.9713086074177746\n",
      "2\n",
      "OriginalRandomForest -ACC: 0.989\n",
      "OriginalRandomForest -REC: 0.9563253012048193\n",
      "OriginalRandomForest -F1: 0.9746738296239448\n",
      "0\n",
      "RandomForest -ACC: 0.9981109012112457\n",
      "RandomForest -REC: 0.9931224209078404\n",
      "RandomForest -F1: 0.9960910554150378\n",
      "1\n",
      "RandomForest -ACC: 0.9866666666666667\n",
      "RandomForest -REC: 0.9559228650137741\n",
      "RandomForest -F1: 0.9719887955182073\n",
      "2\n",
      "RandomForest -ACC: 0.9846666666666667\n",
      "RandomForest -REC: 0.9518072289156626\n",
      "RandomForest -F1: 0.9648854961832061\n",
      "0\n",
      "Adaboost -ACC: 0.962773641515724\n",
      "Adaboost -REC: 0.9211370930765704\n",
      "Adaboost -F1: 0.9230415805191822\n",
      "1\n",
      "Adaboost -ACC: 0.9543333333333334\n",
      "Adaboost -REC: 0.8980716253443526\n",
      "Adaboost -F1: 0.9049271339347675\n",
      "2\n",
      "Adaboost -ACC: 0.9583333333333334\n",
      "Adaboost -REC: 0.911144578313253\n",
      "Adaboost -F1: 0.9063670411985019\n",
      "0\n",
      "LogisticRegression -ACC: 0.7879764418268697\n",
      "LogisticRegression -REC: 0.35488308115543327\n",
      "LogisticRegression -F1: 0.44791666666666663\n",
      "1\n",
      "LogisticRegression -ACC: 0.7776666666666666\n",
      "LogisticRegression -REC: 0.32231404958677684\n",
      "LogisticRegression -F1: 0.41233480176211457\n",
      "2\n",
      "LogisticRegression -ACC: 0.7906666666666666\n",
      "LogisticRegression -REC: 0.3147590361445783\n",
      "LogisticRegression -F1: 0.39961759082217974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "    \n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "          \n",
    "    \n",
    "\n",
    "f_v=features.values\n",
    "f_names=features.columns.values\n",
    "    \n",
    "models = []\n",
    "models.append((\"KNN\",KNeighborsClassifier(n_neighbors=3,n_jobs=-1)))\n",
    "models.append((\"GaussianNB\",GaussianNB()))\n",
    "models.append((\"BernoulliNB\",BernoulliNB()))\n",
    "models.append((\"DecisionTreeGini\",DecisionTreeClassifier()))\n",
    "models.append((\"DecisionTreeEntropy\",DecisionTreeClassifier(criterion=\"entropy\")))\n",
    "models.append((\"SVM Classifier\",SVC(C=1000)))\n",
    "models.append((\"OriginalRandomForest\",RandomForestClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier(n_estimators=11,max_features=None,n_jobs=-1)))\n",
    "models.append((\"Adaboost\",AdaBoostClassifier(n_estimators=100)))\n",
    "# sag 随机梯度下降\n",
    "models.append((\"LogisticRegression\",LogisticRegression(C=1000,tol=1e-10,solver=\"sag\",max_iter=10000)))\n",
    "\n",
    "  \n",
    "      \n",
    "for clf_name,clf in models:\n",
    "    clf.fit(X_train,Y_train)\n",
    "    xy_lst=[(X_train,Y_train),(X_validation,Y_validation),(X_test,Y_test)]\n",
    "    for i in range(len(xy_lst)):\n",
    "        X_part=xy_lst[i][0]\n",
    "        Y_part=xy_lst[i][1]\n",
    "        Y_pred=clf.predict(X_part)\n",
    "        print(i)\n",
    "        print(clf_name,\"-ACC:\",accuracy_score(Y_part,Y_pred))\n",
    "        print(clf_name,\"-REC:\",recall_score(Y_part,Y_pred))\n",
    "        print(clf_name,\"-F1:\",f1_score(Y_part,Y_pred)) \n",
    "#         if clf_name.startswith(\"DecisionTree\"):\n",
    "#             dot_data=StringIO()\n",
    "#             export_graphviz(clf,out_file=dot_data,\n",
    "#                                      feature_names=f_names,\n",
    "#                                      class_names=[\"NL\",\"L\"],\n",
    "#                                      filled=True,\n",
    "#                                      rounded=True,\n",
    "#                                      special_characters=True)\n",
    "#             graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "#             graph.write_pdf(\"dt_tree_%s.pdf\"%(clf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [-0.16009483  0.01494029 -0.04196149  0.03202485  0.05320615 -0.05465984\n",
      " -0.01616189 -0.10639539  0.09246624  0.01392915 -0.01076429 -0.06050522\n",
      "  0.0146708   0.04922629 -0.04760503  0.0122534  -0.00939767  0.00951584\n",
      "  0.02061428  0.0219916 ]\n",
      "MSE: 0.14230903029941022\n",
      "MAE: 0.3019494008573236\n",
      "R2: 0.2154927025916843\n"
     ]
    }
   ],
   "source": [
    "# print(\"X\",features)\n",
    "# print(\"Y\",label)\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "#regr=LinearRegression()\n",
    "regr=Ridge(alpha=1)\n",
    "regr.fit(features.values,label.values)\n",
    "Y_pred=regr.predict(features.values)\n",
    "print(\"Coef:\",regr.coef_)\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "print(\"MSE:\",mean_squared_error(label.values,Y_pred))\n",
    "print(\"MAE:\",mean_absolute_error(label.values,Y_pred))\n",
    "print(\"R2:\",r2_score(label.values,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
